{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e81160cc-585c-4036-9580-cfb9e712544e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed_image\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Generate and save the dog image (replace 'generated_image.jpg' with your desired filename)\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m generate_dog_image()\n\u001b[0;32m     46\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39msave_img(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, generated_image\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDog image generated and saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m, in \u001b[0;36mgenerate_dog_image\u001b[1;34m(noise_level)\u001b[0m\n\u001b[0;32m     35\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m model(noise)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# De-process and scale the output\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m processed_image \u001b[38;5;241m=\u001b[39m deprocess_and_scale(intermediate_output)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Additional processing steps can be added here to guide the image content towards a dog-like appearance (e.g., using loss function engineering or cGANs)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m processed_image\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mdeprocess_and_scale\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Mean and standard deviation values used for centering ImageNet data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m imagenet_mean \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;241m103.94\u001b[39m, \u001b[38;5;241m116.775\u001b[39m, \u001b[38;5;241m123.68\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m x[:, \u001b[38;5;241m0\u001b[39m, :, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m imagenet_mean[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Add mean back to each channel\u001b[39;00m\n\u001b[0;32m     11\u001b[0m x[:, \u001b[38;5;241m1\u001b[39m, :, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m imagenet_mean[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     12\u001b[0m x[:, \u001b[38;5;241m2\u001b[39m, :, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m imagenet_mean[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Function to deprocess the output and convert it to a valid image format\n",
    "def deprocess_and_scale(x):\n",
    "  \"\"\"Deprocesses and scales the output image tensor to be displayed.\"\"\"\n",
    "  # Mean and standard deviation values used for centering ImageNet data\n",
    "  imagenet_mean = tf.constant([103.94, 116.775, 123.68])\n",
    "\n",
    "  x[:, 0, :, :] += imagenet_mean[0]  # Add mean back to each channel\n",
    "  x[:, 1, :, :] += imagenet_mean[1]\n",
    "  x[:, 2, :, :] += imagenet_mean[2]\n",
    "\n",
    "  x *= 255.0  # Scale to 0-255 range\n",
    "  x = tf.clip_by_value(x, 0.0, 255.0)  # Clip to valid pixel range\n",
    "  return tf.cast(x, tf.uint8)\n",
    "\n",
    "\n",
    "# Define the noise generation function (adjustable for noise distribution and magnitude)\n",
    "def generate_noise(shape=(1, 224, 224, 3), noise_level=0.1):\n",
    "    \"\"\"Generates random noise with a specific shape and noise level.\"\"\"\n",
    "    return tf.random.normal(shape=shape) * noise_level\n",
    "\n",
    "# Load the pre-trained VGG16 model with pre-trained weights and exclude top layers\n",
    "model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Main function to generate and process the dog image\n",
    "def generate_dog_image(noise_level=0.1):\n",
    "    \"\"\"Generates a dog image using the pre-trained model and noise input.\"\"\"\n",
    "\n",
    "    # Generate noise\n",
    "    noise = generate_noise(noise_level=noise_level)\n",
    "\n",
    "    # Pass noise through the model\n",
    "    intermediate_output = model(noise)\n",
    "\n",
    "    # De-process and scale the output\n",
    "    processed_image = deprocess_and_scale(intermediate_output)\n",
    "\n",
    "    # Additional processing steps can be added here to guide the image content towards a dog-like appearance (e.g., using loss function engineering or cGANs)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "# Generate and save the dog image (replace 'generated_image.jpg' with your desired filename)\n",
    "generated_image = generate_dog_image()\n",
    "tf.keras.preprocessing.image.save_img('generated_image.jpg', generated_image.numpy()[0])\n",
    "\n",
    "print(\"Dog image generated and saved as 'generated_image.jpg'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198acb31-5fea-4777-a290-546c2cf3cf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
